## CPU的软中断

主要是一些时钟、网络的IO等会触发中断，中断还分成软中断和硬中断，硬中断的话主要是硬件产生的中断，但是不能长时间占用，所以一般将中断分成两部分，上半部分采用硬中断，这样的话用来快速处理中断。

## 内核态和用户态有什么区别

**用户态就是普通程序运行的环境**，不能直接访问硬件资源（CPU、内存、磁盘）只能通过系统调用让内核代为完成。

**内核态就是操作系统内核运行的模式**，可以访问所有硬件资源，负责内存管理、进程调度、文件系统、驱动等。

 每次切换都需要保存寄存器、堆栈、程序计数器（PC）等状态，**会消耗时间**。  

所以系统设计里经常强调：

“减少用户态与内核态的切换次数” —— 比如 epoll、mmap、io_uring 就是为此而生的。

- 用户态：受限、隔离、安全；
- 内核态：特权级高，可以操作 CPU、内存、网卡等。

## 关于进程的地址空间分布

自上到下为保留区、代码段、数据段、BSS段、堆区、文件映射与匿名映射区、栈区、内核空间

![img](G:\CPP\CS_review\assets\1743039774866-9f858e42-e16f-4187-b1a3-852abee4c5d5.png)

进程的地址空间分布是操作系统管理内存的核心机制之一，通过虚拟内存技术为每个进程提供独立的逻辑内存视图。以下是进程地址空间的主要组成部分及其分布：

1. **代码段（Text Segment）**

- **位置**：通常位于地址空间的最低端。
- **内容**：存放可执行指令（机器码），如程序的函数和只读数据。
- **属性**：只读，防止程序意外修改指令。

**2. 初始化数据段（Data Segment）**

- **内容**：已初始化的全局变量和静态变量（如 `int global = 10;`）。
- **属性**：可读写，生命周期与程序一致。

**3. 未初始化数据段（BSS Segment）**

- **内容**：未初始化的全局变量和静态变量（如 `static int buffer[1000];`），程序启动时自动初始化为零。
- **属性**：可读写，与初始化数据段相邻，通常位于代码段之后。

**4. 堆（Heap）**

- **增长方向**：向高地址扩展。
- **用途**：动态内存分配（如 `malloc()`、`new`），由程序员显式管理。
- **特点**：空间较大但需手动释放，分配效率低于栈。

**5. 内存映射区域（Memory-Mapped Region）**

- **内容**：共享库（如 `libc.so`）、文件映射（`mmap` 系统调用）、匿名内存等。
- **位置**：通常位于堆和栈之间，或高地址区域（如 Linux 64 位的 `0x7f...` 地址范围）。

**6. 栈（Stack）**

- **增长方向**：向低地址扩展。
- **用途**：存储局部变量、函数参数、返回地址等。
- **特点**：自动分配/释放，空间有限，溢出会导致程序崩溃（如递归过深）。

**7. 内核空间（Kernel Space）**

- **位置**：地址空间的高位区域（如 32 位 Linux 的 `0xC0000000` 以上）。
- **权限**：用户进程无法直接访问，需通过系统调用进入内核态。

**其他关键点：**

- **地址空间布局随机化（ASLR）**：现代操作系统随机化各段基址，提升安全性。
- **线程栈**：多线程程序中，每个线程拥有独立栈，通常位于进程地址空间的不同位置。
- **环境变量与参数**：位于栈顶部附近或特定区域，存放命令行参数和环境变量。
- **虚拟内存管理**：通过页表映射到物理内存，允许进程使用不连续的物理内存，并提供内存保护。

**典型布局示例（Linux 64位）：**

从低地址到高地址大致为：

```plain
0x0000000000400000 ── 代码段（Text）
0x0000000000600000 ── 数据段（Data）和 BSS
0x0000000000a00000 ── 堆（Heap）
0x7fxxxxxxxxxxxxxx ── 内存映射区域（共享库等）
0x7fffffffff000000 ── 栈（Stack）
0xffff800000000000 ── 内核空间
```

## 进程和线程的区别

**进程是系统进行资源分配和调度的基本单位。**

**线程是操作系统能够进行运算调度的最小单位。** 线程是进程的子任务，是进程内的执行单元。一个进程至少包含一个线程，一个进程可以同时运行多个线程，这些线程共享同一块内存。

资源开销：

- 进程：由于每个进程都有独立的内存空间，创建和销毁进程的开销较大。进程间切换需要保存和回复整个进程，因此上下文切换成本较高。
- 线程：线程共享相同的内存空间，但又有自己独立的内存空间，创建和销毁线程的开销较小。线程间切换只需要保存和恢复少量的线程上下文，因此线程上下文切换开销较小。

通信与同步：

- 进程：由于简称间相互隔离，进程之间的通信需要使用一些特殊的机制比如管道、消息队列、共享内存、socket等
- 由于线程共享相同的内存空间，他们之间可以直接访问共享数据，线程间通信更加方便。

安全性：

- 进程：由于进程间相互隔离，一个进程的崩溃不会直接影响其他进程的稳定性。
- 线程：由于线程共享相同的内存空间，一个线程的错误可能会影响整个进程的稳定性。

### 什么是僵尸进程？

僵尸进程是指子进程的逻辑已经执行完了，但他的父进程还没有通过`wait()、waitpid()`调用来回收他的资源，所以进程仍然保留在进程表中。

如果父进程已经推出了，子进程会被操作系统交由Init（pid=1）的进程来进行资源的回收。

解决方法就是，比如子进程已经执行完毕后，使用信号`SIGCHLD`告知父进程子进程退出，并且注册`hanlder`自动回收。

## 线程和协程的区别

**线程**是操作系统调度的基本单位，属于进程内的执行单元，每个线程拥有独立的栈和程序计数器，可以独执行任务。多个线程可以共享进程的资源。

**协程**是一种用户级的轻量级线程，他由程序员控制调度，不需要操作系统参与。协程是在一个线程内实现的多任务处理方式，协程之间通过显示的让出控制权实现并发。

## 时间片轮转是什么？

时间片轮转是一种调度算法，用在多个进程使用CPU的调度上，防止某个进程长时间占用CPU资源而导致的其他进程阻塞。每个进程分配一个时间片，通常为几毫秒，每个进程按顺序被分配CPU，执行一个时间片后，如果进程还未完成，会被抢占，CPU则会转交执行下一个进程，但时间片耗尽时，当前写成挂起，进程按照一个循环的顺序以此获得CPU，知道他们完成或者被终止。

## 关于操作系统的四种中断类型

1. **外部中断**

例如网卡收到数据，在CPU执行过程中，网卡收到数据后会通知CPU，网卡出发INTR引脚，发送中断请求（可屏蔽中断），CPU嗅到中断信号，检查中断向量表，查到是网卡的中断，暂停当前程序的执行（保存现场），跳转到执行中断服务程序（比如从网卡读取数据，存进缓冲区），执行完成后，恢复现场，继续执行中断前的指令。

```markdown
CPU：正在执行某个程序的主循环...

网卡：嗡～我收到数据包了！我要通知 CPU！

网卡 → INTR 引脚：发出中断请求（可屏蔽中断）

CPU：嗅到中断信号，检查中断向量表 → 查到这是网卡的中断 → 暂停当前程序执行（保存现场）

CPU → 跳转执行中断服务程序 ISR（比如从网卡读取数据、存进缓冲区）

ISR 执行完毕 → 恢复现场 → 继续执行中断前的那条指令
```

1. **陷阱（系统调用）**

程序代码想要调用操作系统打印字符，调用`printf("hello")`,底层会执行`int 0x80`指令，CPU检测到这条指令，知道这是陷阱中断，查找中断向量表，跳转到系统调用的中断服务例程，然后操作系统处理打印功能（写数据到标准输出），处理完成后，CPU返回到`int 0x80`的下一条指令，程序继续往下执行。

```cpp
程序代码：想调用操作系统打印字符串 → 调用 printf("hello") → 底层会执行 int 0x80 指令

    CPU：检测到 int 0x80 → 知道这是陷阱中断 → 查找中断向量表 → 跳转到系统调用的中断服务例程

    OS：处理打印功能（写数据到标准输出）

    处理完成 → CPU 返回到 int 0x80 的下一条指令 → 程序继续往下执行
```

1. **故障（缺页异常）**

```markdown
CPU：执行一条内存读取指令 → 尝试访问虚拟地址 0x8048A000

MMU：报告这个虚拟页没有映射物理地址 → 抛出缺页异常

CPU：保存现场 → 转入缺页异常处理函数（Page Fault Handler）

内核：判断这是合法访问，但页不在内存，于是从磁盘调入这个页 → 更新页表，建立虚实映射关系

CPU：回到引起异常的那条指令 → 重新执行 → 这次访问就成功了
```

1. **终止（段错误）**

```cpp
程序：野指针访问 → 指针 p = 0x12345678 → *p = 10;

CPU：尝试访问非法地址 → MMU 检测地址非法，不在页表中 → 触发段错误（Segmentation Fault）

操作系统：无法修复 → 调用终止处理程序 → 向进程发送 SIGSEGV 信号

程序崩溃 → 被系统终止 → 打印 core dumped
```

## 程序触发错误了之后又是如何执行的呢，报错的过程是什么？

```cpp
🕓 用户程序执行：int x = 10 / 0;

🚨 CPU 发现除数为 0，无法计算 → 抛出除0异常 → 无法通过继续执行解决

↪ CPU 保存现场 → 查异常中断向量 → 定位除0异常处理函数

⚙ 操作系统接管：发现用户程序除 0 → 向该进程发送 SIGFPE 信号（浮点异常）

🧠 如果程序未捕获该信号 → 直接终止 → 输出 “Floating point exception (core dumped)”
```

## 请解释传统文件传输过程中发生的4次数据拷贝分别是什么？

- 传统文件见传输过程存在4此数据的拷贝，第一次拷贝是由磁盘向PageCache的拷贝（是由DMA完成的），第二次拷贝是由PageCache向用户缓存区的拷贝（是由CPU完成的），第三次拷贝是由用户缓存区向socket缓存区的拷贝（是由CPU完成的），第四次拷贝是由socket缓存区向网卡的拷贝（是由DMA完成的）。并且由于read和write的系统调用，涉及四次上下文切换。

## 为什么`mmap + write`相比传统文件传输减少了一次数据拷贝？

通过内存映射（`mmap`）将内核缓冲区（PageCache）直接映射到用户空间，避免了从PageCache到用户缓冲区的CPU拷贝（传统第二次拷贝）。进程通过`mmap`与内核共享同一块内存区域，用户态直接操作映射后的地址，无需数据搬运。

## 在支持SG-DMA的网卡场景下，`sendfile`如何实现真正的“零拷贝”？

在支持SG-DMA的网卡场景，数据从磁盘拷贝到PageCache属于第一次数据拷贝，接着缓冲区文件描述符和数据长度传到socket的缓冲区，SG-DMA控制器可以直接将内核的数据拷贝到网卡的缓冲区，这个过程不需要将数据从操作系统内和拷贝到socket缓冲区，不需要CPU参与拷贝过程，因此称为零拷贝。

## 为什么在大文件传输场景下，零拷贝技术反而可能降低性能？

传输大文件的场景下，如果将大文件移入PageCache的话，由于本身PageCache内存有限，那么PageCache会进行内存交换，很容易把“热点”数据移出PageCache区，导致缓存命中率下降，从而降低性能。所以考虑采用“异步I/O + 直接I/O”形式，就是采用异步的读写操作，然后直接I/O绕过PageCache，直接将磁盘上的数据拷贝到用户缓冲区。直接I/O的缺点是失去了PageCache的预读和合并I/O请求的优化，但对大文件传输来说，这些优化效果有限。

## 写文件到磁盘上的过程是怎么样的？

由用户调用`write()`来唤醒`syscall`，然后进入VFS虚拟文件系统去找`inode/dentry`，来定位文件页的位置，这样就将数据从用户态拷贝到`PageCache`中，然后标记为`dirty`。然后将结果返回给应用，后面操作系统使用异步线程写回脏页，这个过程涉及到文件系统的配合以及NVme驱动或者控制器，然后进行设备的持久化。

```sql
user write()
  -> syscall
     -> VFS: path lookup(dentry/inode), perms
     -> address_space(page cache) 找/建页
     -> copy_from_user -> 标记 dirty
  <- 返回(可能短写; 未必落盘)
[后台]
  balance_dirty_pages 节流
  writeback: ext4(延迟分配/日志) -> bio
  blk-mq -> nvme 驱动/控制器 -> 完成/flush
  清脏
(需要强保证) fsync/fdatasync/msync
```

## malloc() 在分配内存时，会根据用户申请的内存大小选择不同的系统调用？

这个在不同版本的内核中定义的阈值可能不同，一般情况下，当需要开辟的内存小于128malloc的时候采用brk，当需要开辟的内存空间大于128k是，采用mmap，因为brk的内存空间开辟在堆区，当free的时候，内存不会直接释放内存给操作系统，而是将他放到malloc的内存池中，方便下次再次开辟内存空间时分配内存，而mmap开辟的内存空间在文件映射区这与brk不同，并且当释放内存的时候，会将该内存返回给操作系统内核。

- brk 适用于小内存分配（<128KB），它通过调整 **堆顶指针（program break）** 来扩展堆空间，free 后内存不会立即归还 OS，而是缓存在 malloc 的内存池中。
- mmap 适用于大内存分配（≥128KB），它直接在 **文件映射区（匿名映射）** 分配内存，free 后内存会立即归还 OS。
- brk 的缺点：频繁分配和释放小块内存可能导致 内存碎片，因为 free 的内存不会立即归还 OS，而是留在进程的堆里。
- mmap 的缺点：每次分配和释放都会涉及 系统调用 和 缺页中断，开销较大，不适合频繁的小内存操作。

## 为什么 malloc(1) 实际分配的内存远大于 1 字节（如 132KB）？这样的设计有什么优缺点？

内存池管理：malloc会**预分配一块大内存**，避免频繁向操作系统申请内存（减少brk/mmap调用）

减少内存碎片，小内存分配直接从预分配的内存池中切割，避免频繁系统调用和碎片化。

主要还是为了**减少系统调用，提高分配速度、降低碎片化**

## 进程间通信的方式

- **管道/命名管道**

- 单向通信，基于内存或文件适用于父子进程，命名管道解决了即使无血缘关系也可以进行通信
- 但仍未单向通信。

- **消息队列**

- 是由内核维护的链表结构，但消息类型收发，支持多对多通信
- 消息大小首先，频繁通信效率低。适用于低频率的进程间通信场景。

- **共享内存**

- 直接映射同一块物理内存，无需内核的介入，速度最快，因为不需要系统调用。
- 但是需要自行处理同步问题。

- **信号**

- 内核通知进程某事件发生，及时性强。
- 但是信号量小，适用于进程控制（如`kill -9`）

- **信号量**

- 计数器，用于同步而非数据传输，特点就是轻量级，解决竞态条件，需要配合其他IPC使用。

- **socket**

- 跨网络通信，支持不同主机之间的进程通信，通用性强，支持复杂的协议，但是开销比较大（需要协议栈的处理）。

## 产生死锁的四个必要条件，以及如何避免死锁

- **互斥条件**

- 多个线程不能同时使用同一个资源

- **持有并等待条件**

- 线程A在等待资源2的同时并不会释放自己已经持有的资源1

- **不可剥夺条件**

- 在自己使用完之前不能被其他线程获取

- **环路等待条件**

- 两个线程获取资源的顺序构成了环形链。

- **破坏互斥：**某些资源可共享（如只读文件）。
- **破坏持有并等待：**进程必须一次性申请所有资源（可能降低并发性）。
- **破坏不可剥夺：**超时后强制回收资源（如数据库死锁检测）。
- **破坏环路等待：**锁排序（如按固定顺序获取锁A→B→C）。

## 锁的使用

互斥锁（`std::lock_guard``std::unique_lock`）：在协程项目中互斥锁的使用有好几个场景：例如`Scheduler`调度器中需要加全局锁保护任务队列`m_tasks`与线程列表/关闭状态等，再取任务、启动、停止。在具体的协程执行前，还会短暂锁住协程自身的`fiber_mutex`确保状态域`resume()`的原子性。

读写锁（`std::shared_lock``unique_lock`）：在IOManager中需要使用锁保护`m_fdContexts`向量。（`FdContext`结构体主要是一个封装了某个fd对应感兴趣的事件，读写事件以及其对应的事件处理函数），在读多写少的场景下，使用`shared_lock`来读取`FdContext`结构体中的协程，在可进行写入时，可使用`unique_lock`。另外在最小时间堆中，我这里用的是`std::set`，这里在去`getNextTimer()`以及`hasTimer()`中都是使用的读锁，

## 关于多线程的同步问题

| 机制         | 适用场景     | 优点           | 缺点           |
| ------------ | ------------ | -------------- | -------------- |
| **互斥锁**   | 简单临界区   | 简单可靠       | 死锁风险       |
| **读写锁**   | 读多写少     | 读并发高       | 写线程可能饥饿 |
| **条件变量** | 线程间协作   | 精准唤醒       | 虚假唤醒需处理 |
| **自旋锁**   | 极短临界区   | 无上下文切换   | CPU浪费        |
| **信号量**   | 资源池限流   | 灵活控制并发数 | 优先级反转     |
| **无锁编程** | 高性能低延迟 | 无阻塞         | 实现难度高     |

## 有哪些IO模型

1. **阻塞I/O模型**

应用程序读取数据调用`read`,内核需要等待数据准备好没有，如果数据还没有准备好，应用程序被阻塞挂起，程序有运行态->阻塞态，等数据来了（进程有阻塞态->就绪态（等待时间片调度到之后）->运行态），内核在将准备好的数据复制到用户空间，等数据拿到后，完成读取数据后的逻辑。

这个过程应用程序一直等着，CPU空转。

1. **非阻塞I/O模型**

应用程序读取数据调用`read`，如果没有数据，`read`立即返回-1，`errno=EAGAIN`,然后应用程序不断轮询询问数据的完成状态，数据准备好后返回给用户态。不阻塞应用程序，但是应用层轮询开销比较大。通常搭配`select/poll`使用。

1. **I/O复用**

通过一个线程来监控多个I/O操作，一旦某个I/O操作准备就绪，系统会通知应用程序。常见的方式有`select、poll、epoll`通过这些监控socket数据的到来，当数据到来时，就可以告诉用户程序去read。

1. **信号驱动I/O**

就是应用程序设置`O_ASYNC`信号，并设置相应的信号处理函数，此时内核就接收到设置，应用程序可以先干其他的事情，然后等内核收到数据后，就发送`SIGIO`信号，来触发应用程序的信号处理函数，根据信号的信号出来函数执行相应的逻辑后，在进行后续业务的处理。

1. **异步I/O**

应用程序通过`aio_read`发起异步读，内核接收到设置之后后台来监听，内核异步的从设备中读取、复制到用户空间，等读好了之后，通过回调或者事件来告诉应用程序。内核全权负责IO完整流程，应用程序完全非阻塞，也无需轮询，理论上效率最高适合高性能服务器。

## 一致性哈希问题

一致性哈希的好处就是对每一个来的对象做哈希运算后对2^32-1取模，这样就能高保证每一个对象在哈希环上的映射位置相同，再根据顺时针查找最近的节点来选择为某个对象分配的节点，如果说产生哈希倾斜的问题时，则可以根据比如增加虚拟节点来使哈希环上的节点分布更均匀，使用这个的好处主要还是说再动态的增删新结点的时候，数据迁移更小。

## 外部设备的控制器如何通知操作系统

靠中断，一般外部设备的数据准备好了之后，会通过设备控制器向操作系统发送中断，通知操作系统的中断控制器，操作系统保护被中断进程的CPU上下文，转入相应的设备中断处理函数，然后进行终端的处理，执行完成后恢复被中断进程的上下文。

## Reactor模式和Proactor模式的差别在哪？

**Reactor模型**的核心思想是**事件驱动，应用负责处理IO**，也就是说主线程作为反应堆负责等待事件的就绪，一旦有事件就绪，就会通知应用层，回调（handler）应用层自己负责把数据读写出来，再做处理。

Proactor模式是**完成驱动**，核心思想是应用请求IO操作时，把**操作和缓冲区一起**一起交给OS/内核,OS完成IO后，通知应用“IO已完成”,应用层拿到数据直接处理业务逻辑。

## 如果说内存满了怎么办？

正常情况下，比如某个进程要申请一块内存，然后内存空间如果不够了，就需要唤醒这个kswapd的线程来做异步的内存回收，如果说异步回收还不够那么就采用直接回收，但是会阻塞当前进程，如果直接回收还不够，就得用OOM来回收了。

### Kswapd线程的回收机制

这里可以说是回收脏文件页会发生磁盘的IO，因此会影响性能，因为脏的文件需要写到磁盘上，如果是干净的文件页，磁盘上本来就存在，所以直接释放就好了。

```sql
[内存水位 < low] -> 唤醒 kswapd
    |
    v
扫描 LRU 列表 --------> 选择牺牲页
    |                      |
    |                      +--> 脏文件页：触发写回 -> 回收
    |                      +--> 干净文件页：直接回收
    |                      +--> 匿名页：可能换出到 swap
    v
[可用内存 ≥ high] -> kswapd 再次休眠
```

### 如何保证某一个进程不被OOM杀掉呢

Liunx是有一个标准来杀掉某个进程的，会对每个进程进行打分，得分最高的进程会被首先杀掉。

得分有两方面影响：进程已使用的物理内存页面数。每个进程的OOM校准值。

用「系统总的可用页面数」乘以 「OOM 校准值 oom_score_adj」再除以 1000，最后再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Ki 的几率也就越大。

```sql
// points 代表打分的结果
// process_pages 代表进程已经使用的物理内存页面数
// oom_score_adj 代表 00M 校准值
// totalpages 代表系统总的可用页面数
points =process pages + oom score adj*totalpages/1000
```

我们最好将一些很重要的系统服务的 oom_ score_adi 配置为 -1000，比如 sshd，因为这些系统服务一旦被杀掉，我们就很难再登陆进系统了。

但是，不建议将我们自己的业务程序的 oom score adj 设置为 -1000，因为业务程序一旦发生了内存泄漏，而它又不能被杀掉，这就会导致随着它的内存开销变大，OOM kier 不停地被唤醒，从而把其他进程一个个给杀掉。

### 在32位系统上，4G物理内存的机器上，申请8G内存会怎么样？

因为32位操作系统进程最多只能申请3GB大小的虚拟内存空间，所以进程申请8GB内存的话，在申请虚拟内存阶段就会失败。

### 那转变成64位操作系统场景下呢？

因为虚拟内存空间是128T，所以程序申请的虚拟内存如果没有使用，他是不会占物理内存空间的，当访问者快虚拟内存后，操作系统才会进行物理内存的分配。如果申请物理内存超过了空间物理内存的大小，就得看系统有没有开启swap机制，如果没有开启，系统程序就会直接OOM,如果有开启swap，程序可以正常进行。

## Ping回环地址的话过程是什么样的？

`ping `回环地址和 `ping`本机地址，是一样的，走的是`lo0`"假网卡"，都会经过网络层和数据链路层等逻辑，最后在快要出网卡前狠狠拐了个弯，将数据插入到一个链表后就软中断通知 `ksoftirgd `来进行收数据的逻辑，压根就不出网络。所以断网了也能 ping通回环地址。

## 底层磁盘IO

顺序I/O是指**读写操作按照磁盘逻辑地址递增的顺序连续进行，**在硬件层面，磁头只需要顺着轨道连续读/写，不需要频繁的跳转，OS的Page Cache或readahead机制能够提前预取数据，文件系统比如EXT4会尽量把同一文件数据块分配在相邻区域。

随机I/O是指**访问的逻辑地址不连续，**每次读写都可能落到不同的位置上，对于机械硬盘，每次随机IO都需要磁头移动+等待盘片旋转，耗时高，OS层的文件系统元数据也会频繁访问（inode block）。